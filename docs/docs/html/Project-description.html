
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Project description &#8212; Deep learning on SAR data 1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="How to use this repo" href="How-to.html" />
    <link rel="prev" title="Welcome to Deep Learning on SAR data’s documentation!" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="project-description">
<h1>Project description<a class="headerlink" href="#project-description" title="Permalink to this headline">¶</a></h1>
<p>In this project, we apply deep learning (DL) models to analyze SAR data.</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Imagine you are given a satellite image and you need to tell apart the different types of land cover that it represents. If it is an optical image, human eye is pretty good at telling apart water from land, and from built areas, for instance. On SAR satellite images, this becomes a bit more difficult task (such as, telling apart swamp from a water surface).</p>
<p>Such task is called <strong>image segmenation</strong> and there are established methods in traditional computer vision, and in particular, in SAR analytics to perform it.</p>
<p>The task becomes infeasible for a human if it needs to be done on the scale of 100s or 1000s of images in a limited time. Traditional computer vision aproaches suffer from a similar issue as they need to be fine-tuned and adapted to particular datasets, i.e., the human input (from the experts) is still required.</p>
<p>However, deep learning aproaches have a potential to remove such bottlenecks by fully automating the segmentation process.</p>
<div class="section" id="dl-in-computer-vision">
<h3>DL in computer vision<a class="headerlink" href="#dl-in-computer-vision" title="Permalink to this headline">¶</a></h3>
<p>On image data, in general, the DL models perform one of the three main tasks:</p>
<ul class="simple">
<li>classifcation</li>
<li>object detection and localization</li>
<li>semantic segmentation</li>
</ul>
<p>This project focuses on the third task, i.e., the semantic <em>segmentation of SAR images</em>.</p>
</div>
</div>
<div class="section" id="semantic-segmentation">
<h2>Semantic segmentation<a class="headerlink" href="#semantic-segmentation" title="Permalink to this headline">¶</a></h2>
<p id="sem-seg">Semantic segmentation aims at assigning each pixel of the image to an object or area class. Since the revolutionary Fully Convolutional Networks (FCN) paper by Long et al. [Long2015], almost all the state-of-the-art approaches on semantic segmentation are based on this paradigm.</p>
<p>After consulting existing reviews [Garcia2017] and [ReviewOnline2017], and performing our own literature review, we select a number of the state-of-the-art DL models for semantic segmentation and test their applicability on the SAR data in this project.</p>
</div>
<div class="section" id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h2>
<div class="section" id="training-and-test-sar-data">
<h3>Training and test: SAR data<a class="headerlink" href="#training-and-test-sar-data" title="Permalink to this headline">¶</a></h3>
<p>Synthetic aperture radar (SAR) remote sensing systems are based on a radar installed on a moving platform, in our case the satellite. The radar system transmits electromagnetic waves with high power and receives the backscattered signal. Each transmitted pulse interacts with the Earth’s surface and only a portion of it is backscattered to the receiving antenna. The received signals are procesed to form a SAR image.</p>
<p>The advantages of SAR radars are that they can take images at any time of the day (also night) and at any weather unlike the optical remote sensing instruments.</p>
<dl class="docutils">
<dt>Some well-known SAR satellites:</dt>
<dd><ul class="first last simple">
<li>Sentinel-1</li>
<li>RadarSAT</li>
<li>Seasat</li>
<li>TerraSAR-X</li>
<li>Geosat</li>
<li><strong>ICEYE X-1</strong></li>
<li>…</li>
</ul>
</dd>
</dl>
<p>Some challenges for remote sensing and, in particular, for SAR data analytics are that such data are georeferenced, often multi-modal, with particular imaging geometries and there are interpretation difficulties. Given that the current most advancent semantic segmentation DL methods are <strong>supervised</strong>, an additional challenge for DL on the SAR data is the lack of the <em>ground-truth</em> or <em>label data</em>.</p>
</div>
<div class="section" id="labels-corine-data">
<h3>Labels: Corine data<a class="headerlink" href="#labels-corine-data" title="Permalink to this headline">¶</a></h3>
<p>Supervised DL methods require a set of data with ground-truth information to learn from. For semantic segmentation, in particular, it means that we need images in which each pixel is assigned to its object or area class. Such datasets are rare even for the natural/real world images.</p>
<p>The most important datasets for semantic segmentation, such as VOC2012 [VOC2012] and MSCOCO [MSCOCO] are crowdsourced and human-annotated, or completely synthetically created [Synthia2016].</p>
<p>Despite the lack of label data applicable for remote sensing in general, we were happy to discover the <strong>Corine land cover mask</strong> of Europe [Corine1985] initiated in 1985 and updated since then in 2000, 2006 and 2012.</p>
<p>Corine is a program by the EU and stands for <em>coordination of information on the environment</em>. Corine masks provide labeled information for the type of land cover in the EU countries divided into over 40 classes. They are created using initial automatic extraction from the satellite data and additional human experts annotation.</p>
</div>
</div>
<div class="section" id="deep-learning-models">
<h2>Deep learning models<a class="headerlink" href="#deep-learning-models" title="Permalink to this headline">¶</a></h2>
<p>As discussed in Project Description, we start from the existing reviews on semantic segmentation approaches [Garcia2017] and [ReviewOnline2017], and also perform our own literature review in order to select the DL methods to test.</p>
<p>DL methods tested</p>
<ul class="simple">
<li>FC-DenseNets [FCDenseNets]</li>
<li>DeepLabV3 [DeepLabV3]</li>
<li>RefineNet [RefineNet]</li>
<li>ICNet [ICNet]</li>
<li>DeepLabV3+ [DeepLabV3plus]</li>
<li>GCN [GCN]</li>
</ul>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[FCDenseNets] Jégou, Simon, Michal Drozdzal, David Vazquez, Adriana Romero, and Yoshua Bengio. “The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation.” In Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on, pp. 1175-1183. IEEE, 2017.</p>
<p>[DeepLabV3] Chen, Liang-Chieh, George Papandreou, Florian Schroff, and Hartwig Adam. “Rethinking atrous convolution for semantic image segmentation.” arXiv preprint arXiv:1706.05587 (2017).</p>
<p>[RefineNet] Lin, Guosheng, Anton Milan, Chunhua Shen, and Ian Reid. “Refinenet: Multi-path refinement networks for high-resolution semantic segmentation.” In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2017.</p>
<p>[ICNet] Zhao, Hengshuang, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, and Jiaya Jia. “Icnet for real-time semantic segmentation on high-resolution images.” arXiv preprint arXiv:1704.08545 (2017).</p>
<p>[DeepLabV3plus] Chen, Liang-Chieh, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. “Encoder-decoder with atrous separable convolution for semantic image segmentation.” arXiv preprint arXiv:1802.02611 (2018).</p>
<p>[GCN] Peng, Chao, Xiangyu Zhang, Gang Yu, Guiming Luo, and Jian Sun. “Large Kernel Matters–Improve Semantic Segmentation by Global Convolutional Network.” arXiv preprint arXiv:1703.02719 (2017).</p>
<p>[Long2015] Long, Jonathan, Evan Shelhamer, and Trevor Darrell. “Fully convolutional networks for semantic segmentation.” In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440. 2015.</p>
<p>[Garcia2017] Garcia-Garcia, Alberto, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, and Jose Garcia-Rodriguez. “A review on deep learning techniques applied to semantic segmentation.” arXiv preprint arXiv:1704.06857 (2017).</p>
<p>[ReviewOnline2017] A 2017 Guide to Semantic Segmentation with Deep Learning, online <a class="reference external" href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review">http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review</a></p>
<p>[VOC2012] Visual Object Classes Challenge 2012 , online <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/</a></p>
<p>[MSCOCO] Microsoft Common Objects in Context, online <a class="reference external" href="http://cocodataset.org/#home">http://cocodataset.org/#home</a></p>
<p>[Synthia2016] Ros, German, Laura Sellart, Joanna Materzynska, David Vazquez, and Antonio M. Lopez. “The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3234-3243. 2016.</p>
<p>[Corine1985] CORINE Land Cover, online <a class="reference external" href="https://land.copernicus.eu/pan-european/corine-land-cover">https://land.copernicus.eu/pan-european/corine-land-cover</a></p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Deep learning on SAR data</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Project description</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#semantic-segmentation">Semantic segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deep-learning-models">Deep learning models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="How-to.html">How to use this repo</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Welcome to Deep Learning on SAR data’s documentation!</a></li>
      <li>Next: <a href="How-to.html" title="next chapter">How to use this repo</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, sanja7s (Sanja Scepanovic).
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
      |
      <a href="_sources/Project-description.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>